{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "## 1. Find out Python Libraries for Object Detection on Live Video Stream\n",
    "\n",
    "Objects that must be identifiable:\n",
    "* Book\n",
    "* Laptop\n",
    "\n",
    "\n",
    "### COCO dataset (Common Objects in COntext)\n",
    "\n",
    "COCO is a large-scale object detection, segmentation, and captioning dataset from Microsoft.\n",
    "http://cocodataset.org/#home\n",
    "\n",
    "COCO has several features:\n",
    "\n",
    "* Object segmentation\n",
    "* Recognition in context\n",
    "* Superpixel stuff segmentation\n",
    "* 330K images (>200K labeled)\n",
    "* 1.5 million object instances\n",
    "* 80 object categories\n",
    "* 91 stuff categories\n",
    "* 5 captions per image\n",
    "* 250,000 people with keypoints\n",
    "\n",
    "Here are the 80 objetct included in the dataset.\n",
    "Books and Laptops are among them!\n",
    "\n",
    "````\n",
    "person\n",
    "bicycle\n",
    "car\n",
    "motorcycle\n",
    "airplane\n",
    "bus\n",
    "train\n",
    "truck\n",
    "boat\n",
    "traffic light\n",
    "fire hydrant\n",
    "stop sign\n",
    "parking meter\n",
    "bench\n",
    "bird\n",
    "cat\n",
    "dog\n",
    "horse\n",
    "sheep\n",
    "cow\n",
    "elephant\n",
    "bear\n",
    "zebra\n",
    "giraffe\n",
    "backpack\n",
    "umbrella\n",
    "handbag\n",
    "tie\n",
    "suitcase\n",
    "frisbee\n",
    "skis\n",
    "snowboard\n",
    "sports ball\n",
    "kite\n",
    "baseball bat\n",
    "baseball glove\n",
    "skateboard\n",
    "surfboard\n",
    "tennis racket\n",
    "bottle\n",
    "wine glass\n",
    "cup\n",
    "fork\n",
    "knife\n",
    "spoon\n",
    "bowl\n",
    "banana\n",
    "apple\n",
    "sandwich\n",
    "orange\n",
    "broccoli\n",
    "carrot\n",
    "hot dog\n",
    "pizza\n",
    "donut\n",
    "cake\n",
    "chair\n",
    "couch\n",
    "potted plant\n",
    "bed\n",
    "dining table\n",
    "toilet\n",
    "tv\n",
    "laptop\n",
    "mouse\n",
    "remote\n",
    "keyboard\n",
    "cell phone\n",
    "microwave\n",
    "oven\n",
    "toaster\n",
    "sink\n",
    "refrigerator\n",
    "book\n",
    "clock\n",
    "vase\n",
    "scissors\n",
    "teddy bear\n",
    "hair drier\n",
    "toothbrush\n",
    "````\n",
    "\n",
    "\n",
    "\n",
    "### ImageAI\n",
    "A python library built to empower developers to build applications and systems with self-contained Deep Learning and Computer Vision capabilities using simple and few lines of code. \n",
    "https://github.com/OlafenwaMoses/ImageAI\n",
    "\n",
    "Built with simplicity in mind, ImageAI supports a list of state-of-the-art Machine Learning algorithms for image prediction, custom image prediction, object detection, video detection, video object tracking and image predictions trainings. ImageAI currently supports image prediction and training using 4 different Machine Learning algorithms trained on the ImageNet-1000 dataset. ImageAI also supports object detection, video detection and object tracking using RetinaNet, YOLOv3 and TinyYOLOv3 trained on COCO dataset. \n",
    "Eventually, ImageAI will provide support for a wider and more specialized aspects of Computer Vision including and not limited to image recognition in special environments and special fields.\n",
    "\n",
    "#### Object Detection On Live Video Stream\n",
    "https://github.com/OlafenwaMoses/ImageAI/blob/master/imageai/Detection/VIDEO.md\n",
    "\n",
    "ImageAI provides convenient, flexible and powerful methods to perform object detection on videos. The video object detection class provided only supports RetinaNet, YOLOv3 and TinyYOLOv3. This version of ImageAI provides commercial grade video objects detection features, which include but not limited to device/IP camera inputs, per frame, per second, per minute and entire video analysis for storing in databases and/or real-time visualizations and for future insights. To start performing video object detection, you must download the RetinaNet, YOLOv3 or TinyYOLOv3 object detection model via the links below: \n",
    "\n",
    "- RetinaNet (Size = 145 mb, high performance and accuracy, with longer detection time) \n",
    "- YOLOv3 (Size = 237 mb, moderate performance and accuracy, with a moderate detection time) \n",
    "- TinyYOLOv3 (Size = 34 mb, optimized for speed and moderate performance, with fast detection time)\n",
    "\n",
    "Because video object detection is a compute intensive tasks, we advise you perform this experiment using a computer with a NVIDIA GPU and the GPU version of Tensorflow installed. Performing Video Object Detection CPU will be slower than using an NVIDIA GPU powered computer. You can use Google Colab for this experiment as it has an NVIDIA K80 GPU available. \n",
    "\n",
    "### ImageAI - Oficial documentation\n",
    "https://imageai.readthedocs.io/en/latest/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera / Live Stream Video Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Install Anaconda and create a new enviroment for the project\n",
    "\n",
    "I have named it \"swda-env\"\n",
    "#### Activate the enviroment: \n",
    "mariaguinea@mgm:~/Workspace/SWDA_Hackathon$ source activate swda-env\n",
    "\n",
    "#### ImageAI - Dependencies installation (directly on the console!!)\n",
    "\n",
    "pip install pip\n",
    "\n",
    "pip install --upgrade tensorflow \n",
    "\n",
    "pip install numpy\n",
    "\n",
    "pip install scipy\n",
    "\n",
    "pip install opencv-python \n",
    "\n",
    "pip install pillow\n",
    "\n",
    "pip install matplotlib\n",
    "\n",
    "pip install h5py\n",
    "\n",
    "pip install keras \n",
    "\n",
    "\n",
    "#### ImageAI - Installation (directly on the console!!)\n",
    "\n",
    "pip install https://github.com/OlafenwaMoses/ImageAI/releases/download/2.0.2/imageai-2.0.2-py3-none-any.whl \n",
    "\n",
    "#### Download the model and save it\n",
    "https://github.com/OlafenwaMoses/ImageAI/releases/tag/1.0/\n",
    "--> Download and save``yolo.h5``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VideoObjectDetection\n",
    "The VideoObjectDetection class provides you function to detect objects in videos and live-feed from device cameras and IP cameras, using pre-trained models that was trained on the COCO dataset. The models supported are RetinaNet, YOLOv3 and TinyYOLOv3. This means you can detect and recognize 80 different kind of common everyday objects in any video. To get started, download any of the pre-trained model that you want to use via the links below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageai.Detection import VideoObjectDetection\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "#check here for more info https://imageai.readthedocs.io/en/latest/video/index.html\n",
    "\n",
    "execution_path = os.getcwd() #returns current working directory of a process\n",
    "\n",
    "\n",
    "def forFrame(frame_number, output_array, output_count):\n",
    "    print(\"FOR FRAME \" , frame_number)\n",
    "    print(\"Output for each object : \", output_array)\n",
    "    print(\"Output count for unique objects : \", output_count)\n",
    "    print(\"------------END OF A FRAME --------------\")\n",
    "\n",
    "\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "detector = VideoObjectDetection()\n",
    "#set the model according to the downlead pre-trained model\n",
    "detector.setModelTypeAsYOLOv3()\n",
    "detector.setModelPath(os.path.join(execution_path , \"yolo.h5\")) #modify if other model is needed\n",
    "detector.loadModel()\n",
    "\n",
    "\n",
    "detector.detectObjectsFromVideo(camera_input=camera,\n",
    "                                      output_file_path=os.path.join(execution_path, \"camera_detected_video\"),\n",
    "                                      frames_per_second=20,\n",
    "                                      per_frame_function=forFrame,\n",
    "                                      minimum_percentage_probability=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output - Example\n",
    "\n",
    "````\n",
    "FOR FRAME  1\n",
    "Output for each object :  [{'name': 'book', 'percentage_probability': 76.48902535438538, 'box_points': (411, 359, 698, 573)}, {'name': 'refrigerator', 'percentage_probability': 95.99391222000122, 'box_points': (922, 36, 1264, 698)}, {'name': 'laptop', 'percentage_probability': 69.17145848274231, 'box_points': (411, 359, 698, 573)}, {'name': 'cup', 'percentage_probability': 28.488200902938843, 'box_points': (596, 309, 703, 438)}, {'name': 'person', 'percentage_probability': 98.6465334892273, 'box_points': (379, 49, 889, 720)}]\n",
    "Output count for unique objects :  {'book': 1, 'refrigerator': 1, 'laptop': 1, 'cup': 1, 'person': 1}\n",
    "------------END OF A FRAME --------------\n",
    "````\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "* YOLO has better accuracy than YOLO-TINY\n",
    "* Using YOLO model it is possible to detect books and laptops on a strem video using a Intel i7 Processor, 8GB RAM, Intel HD Graphics 1546 MB.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
